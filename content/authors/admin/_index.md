---
# Display name
title: Shiyuan Huang

# Name pronunciation (optional)
# name_pronunciation: Chien Shiung Wu

# Full name (for SEO)
first_name: Shiyuan
last_name: Huang

# Status emoji
status:
  icon: ☕️

# Is this the primary user of the site?
superuser: true

# Role/position/tagline
role: Ph.D. Student

# Organizations/Affiliations to show in About widget
organizations:
  - name: UC Santa Cruz
    url: https://www.ucsc.edu/

# Short bio (displayed in user profile at end of posts)
bio: I am a Ph.D. student in the Department of Computer Science and Engineering at UC Santa Cruz, under the supervision of [Dr. Leilani Gilpin](https://people.ucsc.edu/~lgilpin/) and [Dr. Ian Lane](https://www.linkedin.com/in/ianrlane/). My research primarily revolves around the explainability of NLP models. 

# Interests to show in About widget
interests:
  - Artificial Intelligence
  - Natural Language Processing
  - Explainability, trustworthiness, and hallucination of language models
  # - Large Language Models

# Education to show in About widget
education:
  courses:
    - course: Ph.D. in Computer Science and Engineering
      institution: UC Santa Cruz
    - course: MSc in Computer Science and Engineering
      institution: UC Santa Cruz
      year: 2024
    - course: BSc in Computer Engineering
      institution: UC Santa Cruz
      year: 2022

# Skills
# For available icons, see: https://wowchemy.com/docs/getting-started/page-builder/#icons
# skills:
#   - name: Technical
#     items:
#     - name: Python
#       description: ''
#       percent: 80
#       icon: python
#       icon_pack: fab
#     - name: Data Science
#       description: ''
#       percent: 100
#       icon: chart-line
#       icon_pack: fas
#     - name: SQL
#       description: ''
#       percent: 40
#       icon: database
#       icon_pack: fas
#   - name: Hobbies
#     color: '#eeac02'
#     color_border: '#f0bf23'
#     items:
#       - name: Hiking
#         description: ''
#         percent: 60
#         icon: person-hiking
#         icon_pack: fas
#       - name: Cats
#         description: ''
#         percent: 100
#         icon: cat
#         icon_pack: fas
#       - name: Photography
#         description: ''
#         percent: 80
#         icon: camera-retro
#         icon_pack: fas

# Social/Academic Networking
# For available icons, see: https://wowchemy.com/docs/getting-started/page-builder/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "/#contact" for contact widget.
social:
  - icon: envelope
    icon_pack: fas
    link: 'mailto:shuan101@ucsc.edu'
  # - icon: twitter
  #   icon_pack: fab
  #   link: https://twitter.com/GeorgeCushen
  #   label: Follow me on Twitter
  #   display:
  #     header: true
  - icon: google-scholar # Alternatively, use `google-scholar` icon from `ai` icon pack
    icon_pack: ai
    link: https://scholar.google.com/citations?user=WZZzQLYAAAAJ&hl=en
  - icon: github
    icon_pack: fab
    link: https://github.com/Shiyuan-eric
  - icon: linkedin
    icon_pack: fab
    link: https://www.linkedin.com/in/shiyuan-huang-profile/
  # Link to a PDF of your resume/CV.
  # To use: copy your resume to `static/uploads/resume.pdf`, enable `ai` icons in `params.yaml`,
  # and uncomment the lines below.
  - icon: cv
    icon_pack: ai
    link: uploads/SHIYUAN_CV.pdf

# Highlight the author in author lists? (true/false)
highlight_name: true
---

Shiyuan Huang is a Ph.D. student in the Department of Computer Science and Engineering at UC Santa Cruz, working under the supervision of [Dr. Leilani Gilpin](https://people.ucsc.edu/~lgilpin/) and [Dr. Ian Lane](https://www.linkedin.com/in/ianrlane/). His research focuses on the explainability and trustworthiness of language models, specifically uncovering internal features of large language models to help users better understand and trust them.

His research focuses on evaluating large language models from the perspectives of explainability and trustworthiness, as well as improving both aspects. Currently, he is exploring how likelihood and uncertainty quantification in language model generation can be used to assess their knowledge boundaries and abstention capabilities. He also aims to use these measures to explain why language models perform well or poorly on specific tasks.

<!-- His recent research papers is titled ["Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations"](https://arxiv.org/pdf/2310.11207.pdf). -->
